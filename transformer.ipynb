{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHvKqGxDy6lp",
        "outputId": "640670d9-fc0b-4fb4-9ca6-f3919ce9a945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Nepali_Multi_Modal'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 49 (delta 18), reused 35 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (49/49), 1.79 MiB | 4.68 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Anil-Banjade/Nepali_Multi_Modal.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt3X-xx91tbV",
        "outputId": "4a64f436-c75b-4562-9ba2-3982876c42ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Nepali_Multi_Modal\n"
          ]
        }
      ],
      "source": [
        "%cd Nepali_Multi_Modal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl6HNzuL1zJT",
        "outputId": "e8327fcd-7d1c-442b-e677-520a4131cb64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (1.0.14)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->-r requirements.txt (line 1)) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (0.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 2)) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 1)) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->-r requirements.txt (line 2)) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm->-r requirements.txt (line 1)) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm->-r requirements.txt (line 1)) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm->-r requirements.txt (line 1)) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_5GAZmDr1zMM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer,AutoModel\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVWapl4c1zO3",
        "outputId": "a3487890-1fd2-4e7b-f3d5-7383eb91ae99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Yv82ZXZO1-q3",
        "outputId": "21447b85-f093-4f22-d4d4-24d69a921361"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40444,\n  \"fields\": [\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8091,\n        \"samples\": [\n          \"3139895886_5a6d495b13.jpg\",\n          \"3133825703_359a0c414d.jpg\",\n          \"244910177_7c4ec3f65b.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"caption\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39980,\n        \"samples\": [\n          \"\\u090f\\u0909\\u091f\\u093e \\u0938\\u0947\\u0924\\u094b \\u0915\\u0941\\u0915\\u0941\\u0930 \\u092e\\u0941\\u0916 \\u0916\\u094b\\u0932\\u0947\\u0930 \\u0939\\u093f\\u0909\\u0901\\u0932\\u0947 \\u0922\\u093e\\u0915\\u093f\\u090f\\u0915\\u094b \\u091c\\u092e\\u093f\\u0928\\u092e\\u093e \\u0926\\u094c\\u0921\\u093f\\u0930\\u0939\\u0947\\u0915\\u094b \\u091b\\u0964\",\n          \"\\u090f\\u0915 \\u091c\\u0935\\u093e\\u0928 \\u0915\\u0947\\u091f\\u093e \\u0930 \\u0915\\u0947\\u091f\\u0940 \\u090f\\u0915 \\u0928\\u093f\\u0937\\u094d\\u092a\\u0915\\u094d\\u0937 \\u0916\\u0947\\u0932\\u092e\\u093e \\u090f\\u0915 \\u091c\\u0928\\u093e \\u092e\\u093e\\u0928\\u093f\\u0938\\u0932\\u093e\\u0908 \\u092c\\u0932\\u0932\\u0947 \\u0939\\u093f\\u0930\\u094d\\u0915\\u093e\\u0909\\u0928 \\u0916\\u094b\\u091c\\u093f\\u0930\\u0939\\u0947\\u0915\\u093e \\u091b\\u0928\\u094d\\u0964\",\n          \"\\u090f\\u0915 \\u092c\\u091a\\u094d\\u091a\\u093e \\u092a\\u0943\\u0937\\u094d\\u0920\\u092d\\u0942\\u092e\\u093f\\u092e\\u093e \\u0930\\u0942\\u0916\\u0939\\u0930\\u0942\\u0938\\u0901\\u0917 \\u0905\\u0917\\u094d\\u0932\\u094b \\u0938\\u094d\\u0935\\u093f\\u0902\\u0917 \\u0917\\u0930\\u094d\\u0926\\u0948\\u091b\\u0964\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2335,\n        \"min\": 0,\n        \"max\": 8088,\n        \"num_unique_values\": 8089,\n        \"samples\": [\n          5702,\n          1634,\n          7876\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-99d071c6-1189-48e7-a23d-00ecbc0c7801\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>caption</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>गुलाबी लुगा लगाएको बच्चा प्रवेश गर्ने बाटोमा स...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>काठको भवनमा जाँदै केटी।</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>एउटा सानो केटी काठको प्लेहाउसमा चढ्दै।</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>एउटी सानी केटी आफ्नो खेलघरमा सिँढी चढ्दै।</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1000268201_693b08cb0e.jpg</td>\n",
              "      <td>गुलाबी पोशाक लगाएकी एउटी सानी केटी काठको केबिन...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99d071c6-1189-48e7-a23d-00ecbc0c7801')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99d071c6-1189-48e7-a23d-00ecbc0c7801 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99d071c6-1189-48e7-a23d-00ecbc0c7801');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-236da703-f417-4c76-8ae3-36884c87c80a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-236da703-f417-4c76-8ae3-36884c87c80a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-236da703-f417-4c76-8ae3-36884c87c80a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                       image  \\\n",
              "0  1000268201_693b08cb0e.jpg   \n",
              "1  1000268201_693b08cb0e.jpg   \n",
              "2  1000268201_693b08cb0e.jpg   \n",
              "3  1000268201_693b08cb0e.jpg   \n",
              "4  1000268201_693b08cb0e.jpg   \n",
              "\n",
              "                                             caption  id  \n",
              "0  गुलाबी लुगा लगाएको बच्चा प्रवेश गर्ने बाटोमा स...   0  \n",
              "1                            काठको भवनमा जाँदै केटी।   0  \n",
              "2             एउटा सानो केटी काठको प्लेहाउसमा चढ्दै।   0  \n",
              "3          एउटी सानी केटी आफ्नो खेलघरमा सिँढी चढ्दै।   0  \n",
              "4  गुलाबी पोशाक लगाएकी एउटी सानी केटी काठको केबिन...   0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('datasets/captions.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "8a405e4e1c1c426bbb78dfceb0b43ae9",
            "2ee996add76d42059180372e483ad886",
            "2b680ae0a8894f1a96b8fa573aef4a97",
            "9d01519396864a5daa97fd13f3590f1e",
            "a01e02ebf4ca44f892561df0c5fe08df",
            "9ab71fa76da4454f8c31e5a44a81522a",
            "b72798faf5894263b27e4d2bce0a0c9b",
            "a7fbb0544bfe4af9b04cc4bd6c4f61f6",
            "2282f0f579244baab38d68db33271dd0",
            "17e1fab41df647a7bdd8b31f433ed56e",
            "b4207ea201094e0b8d7d6586536cea0b",
            "8d1f524bd71f4c2491f361524dff1bf7",
            "0097a33fbf91489cb07f2c4147e14621",
            "7b542a833f624a2ea2dd5fb4816dd302",
            "9810880a62d24a2c8f17c23b0a734bba",
            "a7eb9d270b1a4f79b8310fd7d1dd91c1",
            "9b710f27a07749489f5a4394c903c249",
            "b5505cdadd8442b3a74097fff3f93233",
            "94f21152b7eb4c66848153960bbb8174",
            "2105c62db21744b48fcfdeb58dad89fc",
            "aeeb91023d594829a60eabffb0938c28",
            "c4295c18641c4689aaa8f83ad4620b79",
            "67c885e74fdf4b62a8765f9e6dd79d86",
            "c6f58946687040d6b737ffb7de734784",
            "bd92580e627641199b02b0b57e103275",
            "ffb371c9aaae4be6bba9b9ada9735bfa",
            "89e5ecedab4a4f8388505f8078e924a5",
            "0d48fc944ca94453831fdf10680bc4ec",
            "af6f7f2daf594207a7c37d1a56339972",
            "d76c445a92914035abd3be715448a062",
            "39b4b70be9b542648140131f98611941",
            "219903b7d6f44851943cfd1dd57cc999",
            "d2a4a89eadc6471f8e46462c20f73852"
          ]
        },
        "id": "uwT4A0sh2CqG",
        "outputId": "3c4a81ed-dc77-438f-d24a-853b2332f519"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a405e4e1c1c426bbb78dfceb0b43ae9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/652 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d1f524bd71f4c2491f361524dff1bf7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/547k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "67c885e74fdf4b62a8765f9e6dd79d86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tf_model.h5:   0%|          | 0.00/534M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "All TF 2.0 model weights were used when initializing BertModel.\n",
            "\n",
            "All the weights of BertModel were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained('NepBERTa/NepBERTa')\n",
        "text_model = AutoModel.from_pretrained(\"NepBERTa/NepBERTa\",from_tf=True)\n",
        "def get_embeddings(text):\n",
        "  tokens = tokenizer(text, return_tensors=\"pt\", padding=True, max_length=128,truncation=True)\n",
        "  with torch.no_grad():\n",
        "    outputs = text_model(**tokens)\n",
        "    embeddings = outputs.last_hidden_state.squeeze(0)\n",
        "  return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1D1UJ_82Cti",
        "outputId": "cd1977c6-d2b2-4329-f209-b2218c9388ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-8a60cda1e005>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_results = torch.load('/content/drive/MyDrive/Minor_project_try/prefix_and_word.pt')\n"
          ]
        }
      ],
      "source": [
        "loaded_results = torch.load('/content/drive/MyDrive/Minor_project_try/prefix_and_word.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NBXGMGY288E",
        "outputId": "6655c5dc-1c99-46d3-a8d9-b3c829c32d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32359\n",
            "[('गुलाबी लुगा लगाएको बच्चा प्रवेश गर्ने बाटोमा सिँढीको सेट माथि चढिरहेको छ।', tensor([[ 0.0000,  0.1442,  0.0756,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.8039, -0.0351, -0.2620,  ..., -0.1048,  0.7205,  0.0089],\n",
            "        [-0.4068, -0.0525, -0.0864,  ..., -0.2746,  0.2851,  0.2060],\n",
            "        ...,\n",
            "        [-0.4453, -0.1956,  0.2406,  ..., -0.1001, -0.0612,  0.1824],\n",
            "        [-0.8051, -0.0308, -0.2537,  ..., -0.1015,  0.7129,  0.0082],\n",
            "        [-0.8427,  0.0196, -0.2416,  ..., -0.1650,  0.6262, -0.0342]])), ('काठको भवनमा जाँदै केटी।', tensor([[ 0.5239,  0.3402,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.1654,  0.0364, -0.4719,  ...,  0.1318,  0.5413, -0.6919],\n",
            "        [-0.3751,  0.1038,  0.0844,  ..., -0.2974,  0.1548,  0.2263],\n",
            "        ...,\n",
            "        [-0.5258, -0.2756,  0.0506,  ..., -0.1248, -0.1312,  0.1120],\n",
            "        [-0.1676,  0.0371, -0.4867,  ...,  0.0394,  0.4026, -0.6770],\n",
            "        [-0.2306,  0.0808, -0.4887,  ...,  0.0889,  0.5363, -0.6987]])), ('एउटा सानो केटी काठको प्लेहाउसमा चढ्दै।', tensor([[ 0.0000,  0.3930,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.5304, -0.1304, -0.3702,  ..., -0.4309,  0.5350, -0.4676],\n",
            "        [-0.2217, -0.0008,  0.2576,  ..., -0.2901, -0.1778,  0.0854],\n",
            "        ...,\n",
            "        [-0.0454, -0.1012, -0.0140,  ..., -0.1372, -0.0180, -0.4625],\n",
            "        [-0.4593, -0.1326, -0.2561,  ..., -0.4469,  0.3885, -0.4374],\n",
            "        [-0.5876, -0.0938, -0.3781,  ..., -0.4709,  0.5320, -0.4531]])), ('एउटी सानी केटी आफ्नो खेलघरमा सिँढी चढ्दै।', tensor([[ 0.4318,  0.6565,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2143,  0.4472, -0.1864,  ..., -0.1405,  0.8569, -0.0420],\n",
            "        [-0.2837,  0.2899,  0.2965,  ..., -0.3731,  0.1484, -0.1244],\n",
            "        ...,\n",
            "        [-0.0995,  0.2515, -0.0371,  ..., -0.1612,  0.0770, -0.4811],\n",
            "        [-0.2675,  0.4555, -0.1252,  ..., -0.2420,  0.7813, -0.1157],\n",
            "        [-0.2992,  0.4925, -0.2132,  ..., -0.1719,  0.8551, -0.0641]])), ('गुलाबी पोशाक लगाएकी एउटी सानी केटी काठको केबिनमा जाँदै।', tensor([[ 0.0000,  1.8385,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.4149,  0.0684, -0.1862,  ..., -0.1618,  0.9069, -0.3754],\n",
            "        [-0.4479, -0.0511, -0.0859,  ..., -0.2953,  0.2208,  0.2438],\n",
            "        ...,\n",
            "        [-0.2035, -0.5120,  0.2912,  ..., -0.0184,  0.2522, -0.2456],\n",
            "        [-0.4072,  0.0755, -0.0825,  ..., -0.2137,  0.7291, -0.4080],\n",
            "        [-0.4966,  0.1650, -0.2109,  ..., -0.2370,  0.8816, -0.3971]]))]\n"
          ]
        }
      ],
      "source": [
        "print(len(loaded_results))\n",
        "print(loaded_results[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RGtxek9y28-_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TEPj414e2LLN"
      },
      "outputs": [],
      "source": [
        "class config:\n",
        "  emb_dim = 768\n",
        "  num_heads = 8\n",
        "  num_layers = 6\n",
        "  vocab_size = 30522\n",
        "  dropout = 0.1\n",
        "  context_length = 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "MsqCFCJ32LN0"
      },
      "outputs": [],
      "source": [
        "# Layer Normalization\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self,emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(config.emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(config.emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MHE2wl-f2LQm"
      },
      "outputs": [],
      "source": [
        "# GELU Activation\n",
        "class GELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FqQFrsAi2LTW"
      },
      "outputs": [],
      "source": [
        "# Feed-Forward Network\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(config.emb_dim, 4 * config.emb_dim),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * config.emb_dim, config.emb_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "JKBlxWcm2Lxu"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def get_attention_mask(self, seq_len, device):\n",
        "        # Create mask dynamically based on sequence length\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool()\n",
        "        return mask.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, _ = x.shape\n",
        "        device = x.device\n",
        "        \n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn_scores = queries @ keys.transpose(2, 3) / (self.head_dim ** 0.5)\n",
        "        \n",
        "        # Get mask for current sequence length\n",
        "        mask = self.get_attention_mask(num_tokens, device)\n",
        "        attn_scores.masked_fill_(mask, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        context = (attn_weights @ values).transpose(1, 2).contiguous().view(b, num_tokens, self.d_out)\n",
        "        return self.out_proj(context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "RiEPJZl-2L0K"
      },
      "outputs": [],
      "source": [
        "# Positional Embedding\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(config.context_length, config.emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        positions = torch.arange(seq_len, device=x.device).expand(x.size(0), seq_len)\n",
        "        return x + self.emb(positions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-eScpBJ_2L3A"
      },
      "outputs": [],
      "source": [
        "# Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ln1 = LayerNorm(config.emb_dim)\n",
        "        self.attention = MultiHeadAttention(\n",
        "            d_in=config.emb_dim,\n",
        "            d_out=config.emb_dim,\n",
        "            context_length=config.context_length,\n",
        "            dropout=config.dropout,\n",
        "            num_heads=config.num_heads\n",
        "        )\n",
        "        self.ln2 = LayerNorm(config.emb_dim)\n",
        "        self.ffn = FeedForward()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attention(self.ln1(x))\n",
        "        x = x + self.ffn(self.ln2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0kGARKOA2dmx"
      },
      "outputs": [],
      "source": [
        "# Full Transformer Model\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,tokenizer):\n",
        "        super().__init__()\n",
        "        self.tokenizer=tokenizer\n",
        "        self.pos_emb = PositionalEmbedding()\n",
        "        self.blocks = nn.Sequential(*[TransformerBlock() for _ in range(6)])\n",
        "        self.final_ffn = FeedForward()\n",
        "        self.output_layer = nn.Linear(config.emb_dim, config.vocab_size)\n",
        "\n",
        "    def forward(self, combined_embeddings):\n",
        "        x = self.pos_emb(combined_embeddings)\n",
        "        x = self.blocks(x)\n",
        "        x = self.final_ffn(x)\n",
        "        logits=self.output_layer(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Z0SCxtCD_aq6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "I6zVSkeI2dpG"
      },
      "outputs": [],
      "source": [
        "class CaptionEmbeddingDataset(Dataset):\n",
        "  def __init__(self,loaded_results):\n",
        "    self.captions=[item[0] for item in loaded_results]\n",
        "    self.embeddings=[item[1] for item in loaded_results]\n",
        "  def __len__(self):\n",
        "    return len(self.captions)\n",
        "  def __getitem__(self,idx):\n",
        "    return self.captions[idx],self.embeddings[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjr3WjlC7bn2",
        "outputId": "7848aad4-ffa4-4524-b4f7-2ff43afa0dfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('गुलाबी लुगा लगाएको बच्चा प्रवेश गर्ने बाटोमा सिँढीको सेट माथि चढिरहेको छ।',\n",
              " tensor([[ 0.0000,  0.1442,  0.0756,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [-0.8039, -0.0351, -0.2620,  ..., -0.1048,  0.7205,  0.0089],\n",
              "         [-0.4068, -0.0525, -0.0864,  ..., -0.2746,  0.2851,  0.2060],\n",
              "         ...,\n",
              "         [-0.4453, -0.1956,  0.2406,  ..., -0.1001, -0.0612,  0.1824],\n",
              "         [-0.8051, -0.0308, -0.2537,  ..., -0.1015,  0.7129,  0.0082],\n",
              "         [-0.8427,  0.0196, -0.2416,  ..., -0.1650,  0.6262, -0.0342]]))"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x=CaptionEmbeddingDataset(loaded_results)\n",
        "x.__getitem__(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xfr5k3I82dr5",
        "outputId": "10b7d623-2ae2-4534-9856-2041a39356aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([25, 768])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.__getitem__(0)[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "NrsSm8YU72D-"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  captions,embeddings=zip(*batch)\n",
        "  max_len=max(emb.shape[0] for emb in embeddings)\n",
        "  padded_embeddings=[]\n",
        "  for emb in embeddings:\n",
        "    padding_len=max_len-emb.shape[0]\n",
        "    padded_emb=torch.nn.functional.pad(emb, (0, 0, 0, padding_len))\n",
        "    padded_embeddings.append(padded_emb)\n",
        "  padded_embeddings = torch.stack(padded_embeddings)\n",
        "  return captions,padded_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SiE955ae8qSh"
      },
      "outputs": [],
      "source": [
        "dataset=CaptionEmbeddingDataset(loaded_results)\n",
        "dataloader=DataLoader(dataset,batch_size=4,shuffle=True,collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oZI1HWBY9gMx"
      },
      "outputs": [],
      "source": [
        "def validate_shapes(model, dataloader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for captions, embeddings in dataloader:\n",
        "            print(f\"Input embeddings shape: {embeddings.shape}\")\n",
        "\n",
        "            tokens = model.tokenizer(\n",
        "                captions,\n",
        "                return_tensors=\"pt\",\n",
        "                padding=True,\n",
        "                max_length=config.context_length,\n",
        "                truncation=True\n",
        "            )\n",
        "            target_tokens = tokens['input_ids']\n",
        "            print(f\"Target tokens shape: {target_tokens.shape}\")\n",
        "\n",
        "            outputs = model(embeddings.to(device))\n",
        "            print(f\"Initial output shape: {outputs.shape}\")\n",
        "\n",
        "            # Show shapes after alignment and skipping fused embedding\n",
        "            outputs = outputs[:, 1:-1, :]  # Skip first (fused) embedding and last position\n",
        "            targets = target_tokens[:, 1:]  # Skip first token\n",
        "            print(f\"Aligned output shape: {outputs.shape}\")\n",
        "            print(f\"Aligned target shape: {targets.shape}\")\n",
        "\n",
        "            # Show sample data\n",
        "            print(f\"Sample caption: {captions[0]}\")\n",
        "            print(f\"Sample target tokens: {target_tokens[0][:10]}\")\n",
        "\n",
        "            # Additional shape verification\n",
        "            print(f\"\\nAfter reshaping:\")\n",
        "            outputs_flat = outputs.contiguous().view(-1, config.vocab_size)\n",
        "            targets_flat = targets.contiguous().view(-1)\n",
        "            print(f\"Flattened output shape: {outputs_flat.shape}\")\n",
        "            print(f\"Flattened target shape: {targets_flat.shape}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VkLHN8uW9gP2"
      },
      "outputs": [],
      "source": [
        "def train_model(model,dataloader,num_epochs,device):\n",
        "  model=model.to(device)\n",
        "  optimizer=torch.optim.Adam(model.parameters(),lr=1e-4)\n",
        "  criterion=nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss=0\n",
        "\n",
        "    for batch_idx,batch in enumerate(dataloader):\n",
        "      captions, embeddings = batch\n",
        "      embeddings=embeddings.to(device)\n",
        "\n",
        "      tokens=model.tokenizer(captions,return_tensors='pt',padding=True,max_length=128,truncation=True)\n",
        "      target_tokens=tokens['input_ids'].to(device)\n",
        "\n",
        "      outputs=model(embeddings)\n",
        "\n",
        "      outputs=outputs[:,1:-1,:]\n",
        "      targets=target_tokens[:,1:]\n",
        "\n",
        "\n",
        "      outputs = outputs.contiguous().view(-1, config.vocab_size)\n",
        "      targets = targets.contiguous().view(-1)\n",
        "\n",
        "      loss=criterion(outputs,targets)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss+=loss.item()\n",
        "\n",
        "      if batch_idx%100==0:\n",
        "        print(f'Epoch [{epoch}/{num_epochs}], Batch [{batch_idx}/{len(dataloader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    avg_loss=total_loss/len(dataloader)\n",
        "    print(f'Epoch [{epoch}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "X5SrplMM9gSd"
      },
      "outputs": [],
      "source": [
        "config = config()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7YUHcUiE9gVr"
      },
      "outputs": [],
      "source": [
        "dataset=CaptionEmbeddingDataset(loaded_results)\n",
        "dataloader=DataLoader(dataset,batch_size=4,shuffle=True,collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "SnnQNsEVBVZt"
      },
      "outputs": [],
      "source": [
        "model=Transformer(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFaPpzQEBW_E",
        "outputId": "b4e81858-e64a-46f0-8bf9-3b2c18b8f8a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validating shapes:\n",
            "Input embeddings shape: torch.Size([4, 22, 768])\n",
            "Target tokens shape: torch.Size([4, 21])\n",
            "Initial output shape: torch.Size([4, 22, 30522])\n",
            "Aligned output shape: torch.Size([4, 20, 30522])\n",
            "Aligned target shape: torch.Size([4, 20])\n",
            "Sample caption: नुहाउने सूटमा मुस्कुराउँदै केटीहरू बालुवामा बसिरहेका\n",
            "Sample target tokens: tensor([    0,  7893,  2173, 13790,  1861,  9363,  4794,  1908,  1024,  4152])\n",
            "\n",
            "After reshaping:\n",
            "Flattened output shape: torch.Size([80, 30522])\n",
            "Flattened target shape: torch.Size([80])\n",
            "Training model:\n",
            "Epoch [0/1], Batch [0/8090], Loss: 10.3170\n",
            "Epoch [0/1], Batch [100/8090], Loss: 4.1891\n",
            "Epoch [0/1], Batch [200/8090], Loss: 3.2579\n",
            "Epoch [0/1], Batch [300/8090], Loss: 3.0371\n",
            "Epoch [0/1], Batch [400/8090], Loss: 3.3366\n",
            "Epoch [0/1], Batch [500/8090], Loss: 3.3078\n",
            "Epoch [0/1], Batch [600/8090], Loss: 3.4953\n",
            "Epoch [0/1], Batch [700/8090], Loss: 2.5838\n",
            "Epoch [0/1], Batch [800/8090], Loss: 3.0813\n",
            "Epoch [0/1], Batch [900/8090], Loss: 2.1021\n",
            "Epoch [0/1], Batch [1000/8090], Loss: 2.0971\n",
            "Epoch [0/1], Batch [1100/8090], Loss: 2.0012\n",
            "Epoch [0/1], Batch [1200/8090], Loss: 2.1028\n",
            "Epoch [0/1], Batch [1300/8090], Loss: 2.0463\n",
            "Epoch [0/1], Batch [1400/8090], Loss: 1.7885\n",
            "Epoch [0/1], Batch [1500/8090], Loss: 1.9821\n",
            "Epoch [0/1], Batch [1600/8090], Loss: 2.2203\n",
            "Epoch [0/1], Batch [1700/8090], Loss: 1.4272\n",
            "Epoch [0/1], Batch [1800/8090], Loss: 1.1470\n",
            "Epoch [0/1], Batch [1900/8090], Loss: 1.5591\n",
            "Epoch [0/1], Batch [2000/8090], Loss: 1.9502\n",
            "Epoch [0/1], Batch [2100/8090], Loss: 1.3611\n",
            "Epoch [0/1], Batch [2200/8090], Loss: 1.4782\n",
            "Epoch [0/1], Batch [2300/8090], Loss: 1.0218\n",
            "Epoch [0/1], Batch [2400/8090], Loss: 1.3669\n",
            "Epoch [0/1], Batch [2500/8090], Loss: 1.4012\n",
            "Epoch [0/1], Batch [2600/8090], Loss: 1.6101\n",
            "Epoch [0/1], Batch [2700/8090], Loss: 0.9405\n",
            "Epoch [0/1], Batch [2800/8090], Loss: 0.8158\n",
            "Epoch [0/1], Batch [2900/8090], Loss: 1.6737\n",
            "Epoch [0/1], Batch [3000/8090], Loss: 1.0389\n",
            "Epoch [0/1], Batch [3100/8090], Loss: 0.6903\n",
            "Epoch [0/1], Batch [3200/8090], Loss: 1.3716\n",
            "Epoch [0/1], Batch [3300/8090], Loss: 1.0037\n",
            "Epoch [0/1], Batch [3400/8090], Loss: 1.5041\n",
            "Epoch [0/1], Batch [3500/8090], Loss: 0.9328\n",
            "Epoch [0/1], Batch [3600/8090], Loss: 1.3583\n",
            "Epoch [0/1], Batch [3700/8090], Loss: 1.2090\n",
            "Epoch [0/1], Batch [3800/8090], Loss: 0.9930\n",
            "Epoch [0/1], Batch [3900/8090], Loss: 1.3683\n",
            "Epoch [0/1], Batch [4000/8090], Loss: 1.2350\n",
            "Epoch [0/1], Batch [4100/8090], Loss: 1.6865\n",
            "Epoch [0/1], Batch [4200/8090], Loss: 0.9586\n",
            "Epoch [0/1], Batch [4300/8090], Loss: 1.5171\n",
            "Epoch [0/1], Batch [4400/8090], Loss: 1.2222\n",
            "Epoch [0/1], Batch [4500/8090], Loss: 0.6674\n",
            "Epoch [0/1], Batch [4600/8090], Loss: 1.1833\n",
            "Epoch [0/1], Batch [4700/8090], Loss: 1.6555\n",
            "Epoch [0/1], Batch [4800/8090], Loss: 1.0607\n",
            "Epoch [0/1], Batch [4900/8090], Loss: 2.0233\n",
            "Epoch [0/1], Batch [5000/8090], Loss: 1.5503\n",
            "Epoch [0/1], Batch [5100/8090], Loss: 1.0082\n",
            "Epoch [0/1], Batch [5200/8090], Loss: 1.2866\n",
            "Epoch [0/1], Batch [5300/8090], Loss: 1.0059\n",
            "Epoch [0/1], Batch [5400/8090], Loss: 1.0683\n",
            "Epoch [0/1], Batch [5500/8090], Loss: 1.0404\n",
            "Epoch [0/1], Batch [5600/8090], Loss: 1.0373\n",
            "Epoch [0/1], Batch [5700/8090], Loss: 1.3223\n",
            "Epoch [0/1], Batch [5800/8090], Loss: 0.5497\n",
            "Epoch [0/1], Batch [5900/8090], Loss: 1.6181\n",
            "Epoch [0/1], Batch [6000/8090], Loss: 0.8162\n",
            "Epoch [0/1], Batch [6100/8090], Loss: 1.5762\n",
            "Epoch [0/1], Batch [6200/8090], Loss: 1.1399\n",
            "Epoch [0/1], Batch [6300/8090], Loss: 1.3280\n",
            "Epoch [0/1], Batch [6400/8090], Loss: 1.5024\n",
            "Epoch [0/1], Batch [6500/8090], Loss: 1.2982\n",
            "Epoch [0/1], Batch [6600/8090], Loss: 0.9015\n",
            "Epoch [0/1], Batch [6700/8090], Loss: 1.7600\n",
            "Epoch [0/1], Batch [6800/8090], Loss: 0.8341\n",
            "Epoch [0/1], Batch [6900/8090], Loss: 0.9596\n",
            "Epoch [0/1], Batch [7000/8090], Loss: 0.9911\n",
            "Epoch [0/1], Batch [7100/8090], Loss: 1.0206\n",
            "Epoch [0/1], Batch [7200/8090], Loss: 0.8698\n",
            "Epoch [0/1], Batch [7300/8090], Loss: 0.8526\n",
            "Epoch [0/1], Batch [7400/8090], Loss: 1.0622\n",
            "Epoch [0/1], Batch [7500/8090], Loss: 0.7815\n",
            "Epoch [0/1], Batch [7600/8090], Loss: 0.9615\n",
            "Epoch [0/1], Batch [7700/8090], Loss: 0.7186\n",
            "Epoch [0/1], Batch [7800/8090], Loss: 1.3286\n",
            "Epoch [0/1], Batch [7900/8090], Loss: 0.8491\n",
            "Epoch [0/1], Batch [8000/8090], Loss: 1.0948\n",
            "Epoch [0/1], Average Loss: 1.5741\n"
          ]
        }
      ],
      "source": [
        "num_epochs=1\n",
        "\n",
        "print('Validating shapes:')\n",
        "validate_shapes(model,dataloader,device)\n",
        "\n",
        "print('Training model:')\n",
        "train_model(model,dataloader,num_epochs,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgR1CCZBxmKz",
        "outputId": "b7164f85-969d-4c21-d99f-d29ad5014078"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to /content/drive/MyDrive/Minor_project_try/nepali_transformer_model.pt\n"
          ]
        }
      ],
      "source": [
        "def save_model(model, tokenizer, save_path):\n",
        "    # Store config attributes as a dictionary\n",
        "    config_dict = {\n",
        "        'emb_dim': config.emb_dim,\n",
        "        'num_heads': config.num_heads,\n",
        "        'num_layers': config.num_layers,\n",
        "        'vocab_size': config.vocab_size,\n",
        "        'dropout': config.dropout,\n",
        "        'context_length': config.context_length\n",
        "    }\n",
        "\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'config': config_dict,  # Save config attributes instead of the class\n",
        "        'tokenizer': tokenizer\n",
        "    }, save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "# Save your trained model\n",
        "save_path = '/content/drive/MyDrive/Minor_project_try/nepali_transformer_model.pt'\n",
        "save_model(model, tokenizer, save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nm-Owyh0IJ_2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0emqq6FNC0t4"
      },
      "outputs": [],
      "source": [
        "#Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "o9C9ChVbDGj2"
      },
      "outputs": [],
      "source": [
        "def load_model(load_path, device):\n",
        "    # Load checkpoint to CPU first\n",
        "    checkpoint = torch.load(load_path, map_location='cpu')\n",
        "    filtered_state_dict = {\n",
        "        k: v for k, v in checkpoint['model_state_dict'].items() \n",
        "        if k in Transformer(checkpoint['tokenizer']).state_dict()\n",
        "    }\n",
        "    model = Transformer(checkpoint['tokenizer'])\n",
        "    model.load_state_dict(filtered_state_dict, strict=False)\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    return model, checkpoint['tokenizer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oZZz-oFhDO9_"
      },
      "outputs": [],
      "source": [
        "def generate_caption(model, tokenizer, image_embedding, device, max_length=50):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Start with the image embedding\n",
        "        image_embedding = image_embedding.to(device)\n",
        "        current_embeddings = image_embedding.unsqueeze(0)  # [1, 1, 768]\n",
        "        \n",
        "        # Initialize with BOS token embedding\n",
        "        bos_tokens = tokenizer(\"[CLS]\", return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            bos_embedding = get_embeddings(\"[CLS]\").to(device)\n",
        "        current_embeddings = torch.cat([bos_embedding.unsqueeze(0), current_embeddings], dim=1)\n",
        "        \n",
        "        generated_tokens = [tokenizer.cls_token_id]  # Start with [CLS] token\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            # Ensure we don't exceed the model's maximum context length\n",
        "            if current_embeddings.size(1) >= config.context_length:\n",
        "                break\n",
        "                \n",
        "            # Get model predictions\n",
        "            outputs = model(current_embeddings)\n",
        "            \n",
        "            # Get the next token prediction\n",
        "            next_token_logits = outputs[:, -1, :]\n",
        "            \n",
        "            # Apply temperature sampling\n",
        "            temperature = 0.7\n",
        "            scaled_logits = next_token_logits / temperature\n",
        "            probs = torch.softmax(scaled_logits, dim=-1)\n",
        "            \n",
        "            # Filter out special tokens (optional)\n",
        "            # probs[0, tokenizer.all_special_ids] = 0\n",
        "            \n",
        "            next_token = torch.multinomial(probs[0], 1).item()\n",
        "\n",
        "            # Break if we predict the end token\n",
        "            if next_token == tokenizer.sep_token_id:\n",
        "                break\n",
        "\n",
        "            generated_tokens.append(next_token)\n",
        "\n",
        "            # Get embedding for the predicted token\n",
        "            token_text = tokenizer.decode([next_token])\n",
        "            with torch.no_grad():\n",
        "                token_embedding = get_embeddings(token_text).to(device)\n",
        "\n",
        "            # Concatenate with current embeddings\n",
        "            current_embeddings = torch.cat([\n",
        "                current_embeddings,\n",
        "                token_embedding.unsqueeze(0)\n",
        "            ], dim=1)\n",
        "\n",
        "        # Decode the generated tokens\n",
        "        caption = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "        return caption.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "ZixyKYjWGZw2"
      },
      "outputs": [],
      "source": [
        "def run_inference(model_path, test_image_embedding, device):\n",
        "    # Load the model\n",
        "    model, tokenizer = load_model(model_path)\n",
        "\n",
        "    # Generate caption\n",
        "    generated_caption = generate_caption(\n",
        "        model,\n",
        "        tokenizer,\n",
        "        test_image_embedding,\n",
        "        device\n",
        "    )\n",
        "    return generated_caption\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load your saved model and run inference\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model_path='/content/drive/MyDrive/Minor_project_try/nepali_transformer_model.pt'\n",
        "\n",
        "# Get a test image embedding from your dataset\n",
        "test_caption, test_embedding = dataset[0]  # Get first item from dataset\n",
        "image_embedding = test_embedding[0].unsqueeze(0)  # Get just the fused embedding\n",
        "\n",
        "# Run inference\n",
        "generated_caption = run_inference(model_path, image_embedding, device)\n",
        "\n",
        "print(\"Original caption:\", test_caption)\n",
        "print(\"Generated caption:\", generated_caption)\n",
        "\n",
        "def evaluate_model(model, test_dataloader, device, num_samples=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (captions, embeddings) in enumerate(test_dataloader):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "                \n",
        "            try:\n",
        "                # Get the image embedding\n",
        "                image_embedding = embeddings[0][0]  # Get first sample from batch and first token\n",
        "                \n",
        "                # Generate caption\n",
        "                generated_caption = generate_caption(model, tokenizer, image_embedding, device)\n",
        "                \n",
        "                print(f\"\\nSample {i+1}:\")\n",
        "                print(\"Original:\", captions[0])\n",
        "                print(\"Generated:\", generated_caption)\n",
        "                print(\"-\" * 50)\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sample {i}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "# Test the generation\n",
        "print(\"Loading model...\")\n",
        "model, tokenizer = load_model(model_path)\n",
        "print(\"Creating dataloader...\")\n",
        "test_dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
        "print(\"Starting evaluation...\")\n",
        "evaluate_model(model, test_dataloader, device)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0097a33fbf91489cb07f2c4147e14621": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b710f27a07749489f5a4394c903c249",
            "placeholder": "​",
            "style": "IPY_MODEL_b5505cdadd8442b3a74097fff3f93233",
            "value": "vocab.txt: 100%"
          }
        },
        "0d48fc944ca94453831fdf10680bc4ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17e1fab41df647a7bdd8b31f433ed56e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2105c62db21744b48fcfdeb58dad89fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "219903b7d6f44851943cfd1dd57cc999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2282f0f579244baab38d68db33271dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b680ae0a8894f1a96b8fa573aef4a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fbb0544bfe4af9b04cc4bd6c4f61f6",
            "max": 652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2282f0f579244baab38d68db33271dd0",
            "value": 652
          }
        },
        "2ee996add76d42059180372e483ad886": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ab71fa76da4454f8c31e5a44a81522a",
            "placeholder": "​",
            "style": "IPY_MODEL_b72798faf5894263b27e4d2bce0a0c9b",
            "value": "config.json: 100%"
          }
        },
        "39b4b70be9b542648140131f98611941": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67c885e74fdf4b62a8765f9e6dd79d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6f58946687040d6b737ffb7de734784",
              "IPY_MODEL_bd92580e627641199b02b0b57e103275",
              "IPY_MODEL_ffb371c9aaae4be6bba9b9ada9735bfa"
            ],
            "layout": "IPY_MODEL_89e5ecedab4a4f8388505f8078e924a5"
          }
        },
        "7b542a833f624a2ea2dd5fb4816dd302": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f21152b7eb4c66848153960bbb8174",
            "max": 546517,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2105c62db21744b48fcfdeb58dad89fc",
            "value": 546517
          }
        },
        "89e5ecedab4a4f8388505f8078e924a5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a405e4e1c1c426bbb78dfceb0b43ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ee996add76d42059180372e483ad886",
              "IPY_MODEL_2b680ae0a8894f1a96b8fa573aef4a97",
              "IPY_MODEL_9d01519396864a5daa97fd13f3590f1e"
            ],
            "layout": "IPY_MODEL_a01e02ebf4ca44f892561df0c5fe08df"
          }
        },
        "8d1f524bd71f4c2491f361524dff1bf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0097a33fbf91489cb07f2c4147e14621",
              "IPY_MODEL_7b542a833f624a2ea2dd5fb4816dd302",
              "IPY_MODEL_9810880a62d24a2c8f17c23b0a734bba"
            ],
            "layout": "IPY_MODEL_a7eb9d270b1a4f79b8310fd7d1dd91c1"
          }
        },
        "94f21152b7eb4c66848153960bbb8174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9810880a62d24a2c8f17c23b0a734bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeeb91023d594829a60eabffb0938c28",
            "placeholder": "​",
            "style": "IPY_MODEL_c4295c18641c4689aaa8f83ad4620b79",
            "value": " 547k/547k [00:00&lt;00:00, 2.82MB/s]"
          }
        },
        "9ab71fa76da4454f8c31e5a44a81522a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b710f27a07749489f5a4394c903c249": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d01519396864a5daa97fd13f3590f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17e1fab41df647a7bdd8b31f433ed56e",
            "placeholder": "​",
            "style": "IPY_MODEL_b4207ea201094e0b8d7d6586536cea0b",
            "value": " 652/652 [00:00&lt;00:00, 56.1kB/s]"
          }
        },
        "a01e02ebf4ca44f892561df0c5fe08df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7eb9d270b1a4f79b8310fd7d1dd91c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7fbb0544bfe4af9b04cc4bd6c4f61f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeeb91023d594829a60eabffb0938c28": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af6f7f2daf594207a7c37d1a56339972": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4207ea201094e0b8d7d6586536cea0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5505cdadd8442b3a74097fff3f93233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b72798faf5894263b27e4d2bce0a0c9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd92580e627641199b02b0b57e103275": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d76c445a92914035abd3be715448a062",
            "max": 533687680,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39b4b70be9b542648140131f98611941",
            "value": 533687680
          }
        },
        "c4295c18641c4689aaa8f83ad4620b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6f58946687040d6b737ffb7de734784": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d48fc944ca94453831fdf10680bc4ec",
            "placeholder": "​",
            "style": "IPY_MODEL_af6f7f2daf594207a7c37d1a56339972",
            "value": "tf_model.h5: 100%"
          }
        },
        "d2a4a89eadc6471f8e46462c20f73852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d76c445a92914035abd3be715448a062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffb371c9aaae4be6bba9b9ada9735bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219903b7d6f44851943cfd1dd57cc999",
            "placeholder": "​",
            "style": "IPY_MODEL_d2a4a89eadc6471f8e46462c20f73852",
            "value": " 534M/534M [00:02&lt;00:00, 228MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
